---
title: "Homework Bird FeederWatch Data"
format: html
editor: visual
---

[**Overall Analysis of My Bird Feeder Watch Classification Project:**]{.underline}

Since there are 2 different data sets where data set1 ("D1") captures data from 2020-2021 of birds witnessed over a 2 day period. Data set2 ("D2") contains data that captures the amount of bird feeders available in an area, and sometimes the landscape such as the amount of trees, other animals witnessed, etc., but does not list any types of birds witnessed.

Both D1 & D2 list location IDs but the ID alpha-numeric characters do not match up in any way. D1 gives additional information about the longitude and latitude location of where the data was captured, which includes states in the upper NE of the US and as well as in Canada, but the D2 does not give any information at all about where the data was captured, therefore I can't link both of these data sets.

D1 contained no missing values, which makes sense given the short time frame to capture data, compared to 20 years of data captured in D2 which was full of hundreds of thousands of missing data points. I cleaned up D2 by using the "plot_na_pareto" function to find the top 20% that was missing the least amount of data (the function displayed grades of "NotBad", "OK," "Good"), and then I simply removed the rows of data missing values.

Cleaning D2 didn't do much because both "tables" still couldn't be linked in any meaningful way, so I decided to focus my project and analysis on finding what areas offered the most amount of food and will try to link those to the most amount of birds that were witnessed in D1, as a sort of recommended area for the survival of the masses.

It is hard to try to plot any meaningful relationships between these two opposing data sets, D1 & D2, but I will try to include produce something meaningful and include in my Appendix below.

But in summary, it is very difficult to make a decision on where birds should go to if they want to survive based on this limited data and tables I was given. The advantage that birds have over animals that cannot fly is that they can go anywhere (and do go anywhere) to find food in order to survive, and a human can only simply predict that the location with the most amount of food and shelter available and with less predators in the area, the greater chance that we'll observe birds in these favorable locations. And having a bird bath in these locations doesn't necessarily ensure their survival, but it's good to have good hygiene when you're traveling across the world.

\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--

**Background packages installed to run my analysis:**

```{r}

if(!require(pacman))
  install.packages("pacman")

pacman::p_load(
  C50,                # C5.0 Decision Trees and Rule-Based                            # Models
  caret,              # Classification and Regression Training
  e1071,              # Misc Functions of the Department of Statistics (e1071), TU Wien
  keras,              # R Interface to 'Keras'
  kernlab,            # Kernel-Based Machine Learning Lab
  lattice,            # Trellis Graphics for R
  MASS,               # Support Functions and Datasets for Venables and Ripley's MASS
  mlbench,            # Machine Learning Benchmark Problems
  nnet,               # Feedforward Neural Networks and Multinomial Log-Linear Models
  palmerpenguins,     # Palmer Archipelago (Antarctica) Penguin Data
  party,              # A Laboratory for Recursive Partytioning
  partykit,           # A Toolkit for Recursive Partytioning
  randomForest,       # Breiman and Cutler's Random Forests for Classification and Regression
  FSelector,          # This will bring in "RWeka & also randomForest, et al." 
  rJava,              # I think this is needed for RWeka so I'll add it here
  rpart,              # Recursive partitioning models
  RWeka,              # R/Weka Interface
  scales,             # Scale Functions for Visualization
  tidymodels,         # Tidy machine learning framework
  tidyverse,          # Tidy data wrangling and visualization
  xgboost,             # Extreme Gradient Boosting
  snow,
  dlookr, # Exploratory data analysis
  forecast, # Needed for Box-Cox transformations
  formattable, # HTML tables from R outputs
  here, # Standardizes paths to data
  kableExtra, # Alternative to formattable
  knitr, # Needed to write HTML reports
  missRanger, # To generate NAs
  tidyverse) # Powerful data wrangling package suite

### Install packages: Show fewer digits ###

options(digits=3)
```

**Dataset 1 (**This dataset has no missing values.)

[Thoughts on using this data to make a decision tree:]{.underline}

Observations of 10 species of birds were taken from 9 states in the US (NY, PA, VA, CA, MA, TX, OH, NC, MI) and 1 state in Canada (Ontario)... I could combine the data based on vegetation that's observed in Dataset 2 with the longitude and latitude. So given a bird species which area/state would you most likely find it in?

```{r}
### Load raw data.

dataset1 <- read_csv(here('PFW_2021_public.csv'))

dataset1 |>
  #head() |>
  diagnose() |> # 361 birds (species_code)
  formattable()
dataset1

library(writexl)
write_xlsx(dataset1, path = "dataset1_original.xlsx")

dataset1 |> summary()

dataset1 |> # Table of N/A values. Only 3 which I have since removed: snow_dep_atleast, entry_technique, effort_hrs_atleast	
  plot_na_pareto(only_na = TRUE, plot = FALSE) |>
  formattable() # Publishable table

#dataset1 |> # The list of "missing grades" of NA values. 
  #plot_na_pareto(only_na = TRUE, plot = FALSE) # But data has no missing values so this isn't needed.

#dataset1 |> # The plot of "missing grades". But the data has no missing values so this isn't needed either.
  #plot_na_intersect(only_na = TRUE)

dataset1 <- dataset1 |>
##dataset.no_NAs_1 <- dataset1 |> 
  drop_na() # This is part of the alternative classification techniques.

dataset1 |>
  diagnose_category() |>
  formattable()

# Plot showing the results of our imputation
#rpart_na_imp_insulin |>
#  plot()
```

**Dataset 2:**

This has 62 columns of data that has a lot of missing/NA values.\
This is just a basic overview of D2.

```{r}

# All 62 columns in the dataset:
#
#         loc_id,
#         proj_period_id,	
#         yard_type_pavement,
#         yard_type_garden,
#         yard_type_landsca,
#         yard_type_woods,
#         yard_type_desert,
#         hab_dcid_woods,
#         hab_evgr_woods,
#         hab_mixed_woods,
#         hab_orchard,
#         hab_park,
#         hab_water_fresh,
#         hab_water_salt,
#         hab_residential,
#         hab_industrial,
#         hab_agricultural,
#         hab_desert_scrub,
#         hab_young_woods,
#         hab_swamp,
#         hab_marsh,
#         evgr_trees_atleast,
#         evgr_shrbs_atleast,
#         dcid_trees_atleast,	
#         dcid_shrbs_atleast,
#         fru_trees_atleast,
#         cacti_atleast,
#         brsh_piles_atleast,
#         water_srcs_atleast,
#         bird_baths_atleast,
#         nearby_feeders,
#         squirrels,
#         cats,
#         dogs,
#         humans,
#         housing_density,
#         fed_yr_round,
#         fed_in_jan,
#         fed_in_feb,
#         fed_in_mar,
#         fed_in_apr,	
#         fed_in_may,
#         fed_in_jun,
#         fed_in_jul,
#         fed_in_aug,
#         fed_in_sep,
#         fed_in_oct,
#         fed_in_nov,
#         fed_in_dec,
#         numfeeders_suet, (Suet bird feeders are a type of bird feeder that holds suet, a high-energy food source for birds which is especially important during winter when birds need extra energy to stay warm.)
#         numfeeders_ground,
#         numfeeders_hanging,
#         numfeeders_platfrm,
#         numfeeders_humming,
#         numfeeders_water,
#         numfeeders_thistle,
#         numfeeders_fruit,
#         numfeeders_hopper,
#         numfeeders_tube,
#         numfeeders_other,
#         population_atleast,
#         count_area_size_sq_m_atleast)

dataset2 <- read_csv(here('PFW_count_site_data_public_2021.csv'))

dataset2 <- as_tibble(dataset2)
# dataset2 |> glimpse() # Don't use this if there's a lot of columns.
dataset2 |> summary()

dataset2 |>
  head() |>
  formattable()
dataset2

###tree_default <- dataset2 |> # Need to remove N/A columns.
###    rpart(type ~ ., data = _)
###tree_default

###fit <- rpart(dataset2)
###na.rpart(fit)


# fed_data_all_months <- data.frame(dataset2) |>

#dataset2 %>%
#  select(fed_in_apr) #|>
#  ifelse(data == 1, TRUE, FALSE)

#dataset2 <- dataset2 |> # If converting binary data to T/F, use this.
#  mutate(across(where(is.numeric), factor, levels = c(TRUE, FALSE))) |>
#  mutate(across(where(is.character), factor))
# Data type is already factor, so no need to use this.
```

This is my "missing grades" list of how many NA values are in each category -- very valuable since D2 has a lot of missing data. A ratio of missing values below 20%.\
-There are 4 types of bird feeders contained in this data.

This is the D2 that I'm trying to turn into a decision tree, to find the areas/location IDs that classify the best types of data based on number of bird feeders in the area, shelter available, predators present, etc.

**D2 Decision Tree**

```{r}
missing_grades_data <- dataset2 |> # This is the table that guides you on what values to remove.
  plot_na_pareto(only_na = FALSE, plot = FALSE) |>
  formattable()
missing_grades_data

notbad_and_ok_data <- filter(missing_grades_data, grade %in% c("NotBad", "OK", "Good")) 
#This will keep the good variables where, relatively speaking, a minimium of NAs are quite low. Now I want to see if the decision tree algorithm will remove the NAs and plot the data. 
notbad_and_ok_data

#I need to extract these columns then filter the dataset2 for these columns and then clean up the missing values...?

columns_to_export <- c("variable")  #, "ratio", "grade")
write.table(notbad_and_ok_data[, columns_to_export], file = "output.txt", sep = "\t", row.names = FALSE)

columns_to_extract <- c("hab_dcid_woods",
"brsh_piles_atleast",
"hab_water_fresh",
"numfeeders_platfrm",
"hab_mixed_woods",
"numfeeders_ground",
"hab_residential",
"dogs",
"cats",
"evgr_shrbs_atleast",
"dcid_shrbs_atleast",
"nearby_feeders",
"population_atleast",
"evgr_trees_atleast",
"dcid_trees_atleast",
"humans",
"count_area_size_sq_m_atleast",
"housing_density",
"numfeeders_suet",
"squirrels",
"loc_id",
"proj_period_id")

clean_dataset2 <- dataset2[, columns_to_extract]
clean_dataset2 #254,355 rows x 22 columns

no_na_values_dataset2 <- na.omit(clean_dataset2)
no_na_values_dataset2 #121,918 x 22 columns. BEST DATASET so far.

no_na_values_dataset2 <- filter(no_na_values_dataset2, proj_period_id %in% c("PFW_2019", "PFW_2020")) #254,355 rows x 22 columns, before I filter down only to 2019 & 2020 values.

clean_dataset2 <- no_na_values_dataset2[, -22, ] #(19,940 × 21)
clean_dataset2 |> glimpse() # Need to make "loc_id" the target class?

library(writexl)
write_xlsx(clean_dataset2, path = "dataset2_clean.xlsx")

set.seed(2000)
inTrain <- createDataPartition(y = clean_dataset2$loc_id, p = .8, list = FALSE)
dataset2_train <- matrix_clean_dataset2 |> slice(inTrain)
dataset2_test <- matrix_clean_dataset2 |> slice(-inTrain)

knnFit <- matrix_clean_dataset2 |> 
  train(type ~ .,
        data = _,
        method = "knn",
        preProcess = "scale",
          tuneLength = 10,
          trControl = trainControl(method = "cv", indexOut = train_index)
  )
knnFit

knnFit <- matrix_clean_dataset2 |> train(type ~ .,
  method = "knn",
  data = _,
  preProcess = "scale",
    tuneLength = 5,
  tuneGrid=data.frame(k = 1:10),
    trControl = trainControl(method = "cv", indexOut = train_index))
knnFit

#######################################################################
### The following was going to turn birdfeeder counts into factors.
### Maybe ignore for now.
#######################################################################
birdfeeder_count <- c(0:14, 16, 22)
birdfeeder_count
no_of_birdfeeder_elements <- length(birdfeeder_count) 
no_of_birdfeeder_elements # There's 17 elements that need to be divided by 3... So arbitrary 6, 6, 5.

breaks <- quantile(birdfeeder_count, probs = c(0, 1/3, 2/3, 1))
breaks |> summary()
categories <- cut(birdfeeder_count, breaks, include.lowest = TRUE, labels = c("Category 1", "Category 2", "Category 3"))
categories

# Print the categories
print(categories)

####################################################################

#tree_default <- no_na_values_dataset2 |> 
#  rpart(type ~ ., data = _) # I think I need to choose the "response variable" and "predictor" to control my model...?
#tree_default

fit <- rpart(notbad_and_ok_data) #A simple decision tree where I'm not actually controlling the input and output...?
fit
```

**K-Nearest Neighbors**

```{r}

# It's important that I create a full tree with my dataset in order to be able to run real tests to train my data against different classification models.

no_na_values_dataset2
#no_na_values_dataset2 <- no_na_values_dataset2[, !(names(no_na_values_dataset2) %in% c("loc_id", "proj_period_id"))]
matrix_clean_dataset2 <- lapply(no_na_values_dataset2, as.integer)
matrix_clean_dataset2 <- as.matrix(matrix_clean_dataset2)
matrix_clean_dataset2 |> glimpse() # Transforming my list into integers.
```

This is the graph of all missing values, which the "only_na = FALSE" shows the relationship of two density curves, which "only_na = TRUE" has all data colored in red, indicating that all data should be removed.

```{r}

dataset2 |> # This is just the above, but "plot" isn't "FALSE".
  plot_na_pareto(only_na = FALSE)
```

```{r}

#dataset2 |>
#  diagnose_category() |>
#  formattable()

#fed_yr_round_data <- dataset2 %>%
#  select(loc_id,
#         proj_period_id,
#         fed_in_apr,
#         fed_in_aug,
#         fed_in_dec,
#         fed_in_feb,
#         fed_in_jan,
#         fed_in_jul,
#         fed_in_jun,
#         fed_in_mar,
#         fed_in_may,
#         fed_in_nov,
#         fed_in_oct,
#         fed_in_sep) #|>
    #diagnose_category() |>
  #formattable()

#fed_yr_round_data <- dataset2 %>%
#  diagnose_category() |>
#    formattable()
#fed_yr_round_data

#fit <- rpart(fed_yr_round_data) #This WILL produce a decision tree.
#fit

#tree_default <- fed_yr_round_data |> 
#  rpart(type ~ ., data = _)
#tree_default

#tree_full <- fit |> 
#  rpart(type ~ . , data = _, 
#        control = rpart.control(minsplit = 2, cp = 0))
#rpart.plot(tree_full, extra = 2, 
#           roundint=FALSE,
#            box.palette = list("Gy", "Gn", "Bu", "Bn", 
#                               "Or", "Rd", "Pu")) # specify 7 colors

#fed_data_all_months <- data.frame(dataset2) |>
#  group_by(proj_period_id, fed_in_apr, fed_in_may, fed_in_jun, fed_in_aug, #fed_in_dec, fed_in_feb, fed_in_jan, fed_in_jul, fed_in_mar, fed_in_nov, #fed_in_oct, fed_in_sep) |>
#    summarise.groups(count = n())
#fed_data_all_months

#fed_in_apr_data <- dataset2|>
#  group_by("fed_in_apr", "fed_in_may") |>
#    summarise(count = n())

#fed_in_apr_data
```

*Dataset 2 - Observation of unknown areas that account for plants, creatures, habitat, water, etc., throughout the years 2001-2020, which has a lot of gaps in the data.*

*Once I narrow down the data to reliable data, then we can ask, "Can the birds that were observed in Dataset 1 live in the lands listed in Dataset 2?"*

See how much feeding has been done throughout the months over the years.

Think about amount of trees, predators (who will compete for food), etc.
